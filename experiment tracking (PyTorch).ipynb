{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a119edc4",
   "metadata": {},
   "source": [
    "In order to figure out which experiments are worth pursuing, **experiment tracking** comes in\n",
    "\n",
    "In this notebook, example of programatically tracking experiment can be seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07345b47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
    "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "except:\n",
    "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
    "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013c26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# regular imports\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# Try to get torchinfo, install it if it doesn't work\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary\n",
    "\n",
    "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
    "try:\n",
    "    from going_modular import data_setup, engine\n",
    "except:\n",
    "    # Get the going_modular scripts\n",
    "    # Clones github repo\n",
    "    # moves specified directory to root with '.'\n",
    "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
    "    !git clone https://github.com/aayush2058/pytorch_fundamentals\n",
    "    !move pytorch_fundamentals/going_modular .\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed0cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed: int = 42):\n",
    "    '''\n",
    "    Sets random sets for torch operations.\n",
    "    \n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    '''\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb5d97e",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571a96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Food vision dataset (pizza, steak, sushi)\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "def download_zipped_data(source: str,\n",
    "                        destination: str,\n",
    "                        remove_source: bool = True) -> Path:\n",
    "    \"\"\"\n",
    "    Downloads a zipped dataset from source and unzips to destination.\n",
    "    \"\"\"\n",
    "    # Setup path to a data folder\n",
    "    data_path = Path(\"data/\")\n",
    "    image_path = data_path/destination\n",
    "    \n",
    "    # If the image folder doesn't exist, create it\n",
    "    if image_path.is_dir():\n",
    "        print(f\"[INFO] {image_path} directory already exists, skipping download.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"[INFO] Did not find {image_path} directory, creating one...\")\n",
    "        image_path.mkdir(parents = True, exist_ok = True)\n",
    "        \n",
    "        # Download the target data\n",
    "        target_file = Path(source).name # this takes title of the file\n",
    "        with open(data_path / target_file, \"wb\") as f:\n",
    "            request = requests.get(source)\n",
    "            print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
    "            f.write(request.content)\n",
    "            \n",
    "        # Unzip target file\n",
    "        with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
    "            print(f\"[INFO] Unzipping {target_file} data...\")\n",
    "            zip_ref.extractall(image_path)\n",
    "            \n",
    "        # Remove .zip file if needed\n",
    "        if remove_source:\n",
    "            os.remove(data_path / target_file)\n",
    "            \n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/\")\n",
    "image_path = download_zipped_data(source = \"https://github.com/aayush2058/Food-identification-PyTorch-/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                    destination = \"pizza_steak_sushi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b78a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe74e61",
   "metadata": {},
   "source": [
    "#### Walking through data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_path, dir_names, filenames in os.walk(image_path):\n",
    "    print(f\"There are {len(dir_names)} directories and {len(filenames)} images in '{dir_path}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c397fd",
   "metadata": {},
   "source": [
    "### Datasets and DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories\n",
    "train_dir = image_path/\"train\"\n",
    "test_dir = image_path/\"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating manual transformer with normalization labels\n",
    "from going_modular import data_setup\n",
    "from torchvision import transforms\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "manual_transformer = transforms.Compose([\n",
    "                                 transforms.Resize(size = (256, 256)),\n",
    "                                 transforms.CenterCrop(size = [224]),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 normalize])\n",
    "\n",
    "print(f\"Manual transform setup: {manual_transformer}\")\n",
    "\n",
    "# Creating dataloaders\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir = train_dir,\n",
    "                                                                              test_dir = test_dir,\n",
    "                                                                              train_transform = manual_transformer,\n",
    "                                                                              test_transform = manual_transformer, \n",
    "                                                                              batch_size = 32)\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6191aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating automatic transformer\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "# Creating automatic transformer\n",
    "automatic_transformer = weights.transforms()\n",
    "\n",
    "print(f\"Automatic transform setup: {automatic_transformer}\")\n",
    "\n",
    "\n",
    "# Creating dataloaders\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir = train_dir,\n",
    "                                                                              test_dir = test_dir,\n",
    "                                                                              train_transform = automatic_transformer,\n",
    "                                                                              test_transform = automatic_transformer,\n",
    "                                                                              batch_size = 32)\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0127d4",
   "metadata": {},
   "source": [
    "### Getting a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting up to date default weights for this model\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "# creating model with default weights\n",
    "model = torchvision.models.efficientnet_b0(weights = weights).to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8940e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Freeze all the base layers by setting their requires_grad attribute to False.\n",
    "Because PyTorch automatically tracks the gradients of our model parameters and if we want to update them, optimizer do so.\n",
    "So we set requires_grad = False so that those parameters are freezed while training.\n",
    "'''\n",
    "for param in model.features.parameters():\n",
    "    # print(param)\n",
    "    param.requires_grad = False   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00805ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the classifier head\n",
    "print(f\"Default classifier of the model: {model.classifier}\")\n",
    "model.classifier = nn.Sequential(\n",
    "                                nn.Dropout(p = 0.2, inplace = True),\n",
    "                                nn.Linear(in_features = 1280,\n",
    "                                         out_features = len(class_names))).to(device)\n",
    "\n",
    "print(f\"\\nModified classifier for our problem: {model.classifier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7588a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model = model,\n",
    "       input_size = (32, 3, 224, 224),\n",
    "       verbose = 0,\n",
    "       col_names = [\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "       col_width = 20,\n",
    "       row_settings = [\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a993e5e",
   "metadata": {},
   "source": [
    "#### Train a single model and track resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f9fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a summary writer\n",
    "import tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from going_modular.engine import train_step, test_step\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "    Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "              train_acc: [...],\n",
    "              test_loss: [...],\n",
    "              test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "             {train_loss: [2.0616, 1.0537],\n",
    "              train_acc: [0.3945, 0.3945],\n",
    "              test_loss: [1.2641, 1.5706],\n",
    "              test_acc: [0.3400, 0.2973]} \n",
    "    \"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # Make sure model on target device\n",
    "    model.to(device)\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "        \n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        device=device)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        \n",
    "        ##### NEW: Experiment tracking #####\n",
    "        # open writer(SummaryWriter())\n",
    "        writer.add_scalars(main_tag = \"Loss\",\n",
    "                          tag_scalar_dict = {\"train_loss\": train_loss,\n",
    "                                             \"test_loss\": test_loss},\n",
    "                          global_step = epoch)\n",
    "        \n",
    "        writer.add_scalars(main_tag = \"Accuracy\",\n",
    "                          tag_scalar_dict = {\"train_acc\": train_acc,\n",
    "                                             \"test_acc\": test_acc},\n",
    "                          global_step = epoch)\n",
    "        \n",
    "        writer.add_graph(model = model,\n",
    "                        input_to_model = torch.randn(32, 3, 224, 224).to(device)\n",
    "                        )\n",
    "    # close writer\n",
    "    writer.close()\n",
    "    ##### End NEW #####\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed1ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = train(model = model, \n",
    "      train_dataloader = train_dataloader, \n",
    "      test_dataloader = test_dataloader, \n",
    "      optimizer = optimizer,\n",
    "      loss_fn = loss_fn,\n",
    "      epochs = 5,\n",
    "      device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34584059",
   "metadata": {},
   "source": [
    "#### View model's results with Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c53a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing experiments from within the notebook\n",
    "import tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389a2795",
   "metadata": {},
   "source": [
    "### create a functin to prepare a `SummaryWriter()` instance\n",
    "\n",
    "By default our `SummaryWriter()` class saves to `log_dir`.\n",
    "\n",
    "How about if we wanted to save different experiments to different folders?\n",
    "\n",
    "In essence, one experiment = one folder\n",
    "example:\n",
    "   * Experiment data/timestamp\n",
    "   * Experiment name\n",
    "   * Model name\n",
    "   * Extra - is there anything else that should be tracked?\n",
    "    \n",
    "Let's create a function to create a `SummaryWriter()` instance to take all of these things into account.\n",
    "\n",
    "So ideally we end up tracking experiments to a directory:\n",
    "\n",
    "`runs/YYTT-MM-DD/experiment_name/model/model_name/extra`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a595e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def create_writer(experiment_name: str,\n",
    "                 model_name: str,\n",
    "                 extra: str = None):\n",
    "    \"\"\"\n",
    "    Creates a torch.utils.tensorboard.writer.SummaryWriter() instance tracking to a specific directory.\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "    \n",
    "    # Get timestamp of current date in reverse order\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    if extra:\n",
    "        # Create log directory path\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
    "    else:\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "    print(f\"[INFO] Created SummaryWriter saving to {log_dir}\")\n",
    "    return SummaryWriter(log_dir = log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc24eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_writer = create_writer(experiment_name = \"data_10_percent\",\n",
    "                              model_name = 'effnetb0',\n",
    "                              extra = \"5_epochs\")\n",
    "example_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c058cd",
   "metadata": {},
   "source": [
    "### Update the `train()` function to include a `writer` parameter\n",
    "Below function can track multiple experiments if we need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1014b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from going_modular.engine import train_step, test_step\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          writer: torch.utils.tensorboard.writer.SummaryWriter = None) -> Dict[str, List]:\n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "    Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "              train_acc: [...],\n",
    "              test_loss: [...],\n",
    "              test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "             {train_loss: [2.0616, 1.0537],\n",
    "              train_acc: [0.3945, 0.3945],\n",
    "              test_loss: [1.2641, 1.5706],\n",
    "              test_acc: [0.3400, 0.2973]} \n",
    "    \"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # Make sure model on target device\n",
    "    model.to(device)\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "        \n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        device=device)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        \n",
    "        ##### NEW: Experiment tracking #####\n",
    "        if writer:\n",
    "            # open writer(SummaryWriter())\n",
    "            writer.add_scalars(main_tag = \"Loss\",\n",
    "                              tag_scalar_dict = {\"train_loss\": train_loss,\n",
    "                                                 \"test_loss\": test_loss},\n",
    "                              global_step = epoch)\n",
    "\n",
    "            writer.add_scalars(main_tag = \"Accuracy\",\n",
    "                              tag_scalar_dict = {\"train_acc\": train_acc,\n",
    "                                                 \"test_acc\": test_acc},\n",
    "                              global_step = epoch)\n",
    "\n",
    "            writer.add_graph(model = model,\n",
    "                            input_to_model = torch.randn(32, 3, 224, 224).to(device)\n",
    "                            )\n",
    "            # close writer\n",
    "            writer.close()\n",
    "            ##### End NEW #####\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979644f4",
   "metadata": {},
   "source": [
    "### Setting up a series of model experiments\n",
    "\n",
    "Example: \n",
    "Setup two procedures for same dataset and train for different epochs value to track experiments between two procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01d23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_1 = create_writer(experiment_name = \"data_10_percent\",\n",
    "                              model_name = 'effnetb0',\n",
    "                              extra = \"5_epochs_SGD_optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aed4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = train(model = model, \n",
    "          train_dataloader = train_dataloader, \n",
    "          test_dataloader = test_dataloader, \n",
    "          optimizer = torch.optim.SGD(model.parameters(), lr = 0.01),\n",
    "          loss_fn = loss_fn,\n",
    "          epochs = 5,\n",
    "          device = device,\n",
    "          writer = writer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1506577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import plot_loss_curves\n",
    "plot_loss_curves(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914df3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c195e5",
   "metadata": {},
   "source": [
    "### To compare different models and run limitless experiments,\n",
    "\n",
    "* Change the number of epochs\n",
    "* Change the number of hidden layers/units\n",
    "* Change the amount of data (right now we're using 10% of the Food101 dataset for pizza, steak, sushi)\n",
    "* Change the learning rate\n",
    "* Try different kinds of data augmentation\n",
    "* Choose a different model architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe4478",
   "metadata": {},
   "source": [
    "### What experiments are we going to run?\n",
    "\n",
    "We're going to turn three dials:\n",
    "1. Model size - EfficientNetB0 vs EfficientNetB2\n",
    "2. Dataset size - 10% of pizza, steak, sushi images vs 20% (generally, more data = better results)\n",
    "3. Training time - 5 epochs vs 10 epochs (generally longer training time = better results, up to a point)\n",
    "\n",
    "To begin, we're still keeping things relatively small so that our experiments run quickly.\n",
    "\n",
    "**Our goal:** a model that is well performing but still enough to run on a mobile device or web browser, so FoodVision Mini can come to life.\n",
    "\n",
    "If you had infinite compute + time, you should basically always choose the biggest model and biggest dataset you can."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbef402",
   "metadata": {},
   "source": [
    "## Another project workflow starts\n",
    "\n",
    "#### Download different datasets\n",
    "\n",
    "We want two datasets:\n",
    "1. pizza_steak_sushi 10%\n",
    "2. pizza_steak_sushi 20%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download zipped data and extract into the directory\n",
    "\n",
    "pizza_steak_suushi_10 = download_zipped_data(source = \"https://github.com/aayush2058/pytorch_fundamentals/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                                            destination = \"pizza_steak_sushi_10\",\n",
    "                                            remove_source = True)\n",
    "\n",
    "\n",
    "pizza_steak_suushi_20 = download_zipped_data(source = \"https://github.com/aayush2058/pytorch_fundamentals/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
    "                                            destination = \"pizza_steak_sushi_20\",\n",
    "                                            remove_source = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image path for 20%_data\n",
    "image_path_10 = Path(\"data/pizza_steak_sushi_10\")\n",
    "image_path_10\n",
    "\n",
    "# image path for 20%_data\n",
    "image_path_20 = Path(\"data/pizza_steak_sushi_20\")\n",
    "image_path_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847725ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walking thorugh pizza_stek_sushi_10%\n",
    "\n",
    "for dir_path, dir_names, filenames in os.walk(image_path_10):\n",
    "    print(f\"There are {len(dir_names)} directories and {len(filenames)} images in '{dir_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walking through pizza_steak_sushi_20%\n",
    "\n",
    "for dir_path, dir_names, filenames in os.walk(image_path_20):\n",
    "    print(f\"There are {len(dir_names)} directories and {len(filenames)} images in '{dir_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 10% data and 20% data\n",
    "train_dir_10 = image_path_10/\"train\"\n",
    "train_dir_20 = image_path_20/\"train\"\n",
    "\n",
    "# Test dir remains same to compare between the performance of models\n",
    "test_dir = image_path_10/\"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f806009",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d613a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating automatic transformer\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "# Creating automatic transformer\n",
    "automatic_transformer = weights.transforms()\n",
    "\n",
    "print(f\"Automatic transform setup: {automatic_transformer}\")\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "# Creating dataloaders for 10%\n",
    "train_dataloader_10, test_dataloader_10, class_names_10 = data_setup.create_dataloaders(train_dir = train_dir_10,\n",
    "                                                                              test_dir = test_dir,\n",
    "                                                                              train_transform = automatic_transformer,\n",
    "                                                                              test_transform = automatic_transformer,\n",
    "                                                                              batch_size = BATCH_SIZE)\n",
    "\n",
    "train_dataloader_20, test_dataloader_20, class_names_20 = data_setup.create_dataloaders(train_dir = train_dir_20,\n",
    "                                                                              test_dir = test_dir,\n",
    "                                                                              train_transform = automatic_transformer,\n",
    "                                                                              test_transform = automatic_transformer,\n",
    "                                                                              batch_size = BATCH_SIZE)\n",
    "\n",
    "train_dataloader_10, test_dataloader_10, class_names_10, train_dataloader_20, test_dataloader_20, class_names_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of batches of size {BATCH_SIZE} in 10% train data: {len(train_dataloader_10)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 20% train data: {len(train_dataloader_20)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41eee0",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac97b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effnetb2\n",
    "# getting up to date default weights for this model\n",
    "weights_efnetb0 = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "# creating model with default weights\n",
    "effnetb0 = torchvision.models.efficientnet_b0(weights = weights_efnetb0).to(device)\n",
    "effnetb0.to(device)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Effnetb2\n",
    "# getting up to date default weights for this model\n",
    "weights_efnetb2 = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
    "\n",
    "# creating model with default weights\n",
    "effnetb2 = torchvision.models.efficientnet_b2(weights = weights_efnetb2).to(device)\n",
    "effnetb2.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbe70c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model = effnetb0,\n",
    "       input_size = (32, 3, 224, 224),\n",
    "       verbose = 0,\n",
    "       col_names = [\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "       col_width = 20,\n",
    "       row_settings = [\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14429fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model = effnetb2,\n",
    "       input_size = (32, 3, 224, 224),\n",
    "       verbose = 0,\n",
    "       col_names = [\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "       col_width = 20,\n",
    "       row_settings = [\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8573cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze base model layers\n",
    "\n",
    "set_seeds(seed = 42)\n",
    "\n",
    "for param in effnetb0.features.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in effnetb2.features.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Change classifier head\n",
    "effnetb0.classifier = nn.Sequential(\n",
    "                                    nn.Dropout(p=0.3, inplace=True),\n",
    "                                    nn.Linear(in_features=1280, \n",
    "                                           out_features=len(class_names_10))\n",
    "                                    )\n",
    "\n",
    "effnetb2.classifier = nn.Sequential(\n",
    "                                    nn.Dropout(p=0.3, inplace=True),\n",
    "                                    nn.Linear(in_features=1408, \n",
    "                                           out_features=len(class_names_10))\n",
    "                                    )\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33774a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model = effnetb0,\n",
    "       input_size = (32, 3, 224, 224),\n",
    "       verbose = 0,\n",
    "       col_names = [\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "       col_width = 20,\n",
    "       row_settings = [\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6361055",
   "metadata": {},
   "source": [
    "#### Create experiments and setup training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72b58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create epoch list\n",
    "num_epochs = [5, 10]\n",
    "\n",
    "# Create models list (need to create a new model for each experiment)\n",
    "models = [\"effnetb0\", \"effnetb2\"]\n",
    "\n",
    "# Create a DataLoaders dictionary\n",
    "train_dataloaders = {\"data_10_percent\": train_dataloader_10,\n",
    "                    \"data_20_percent\": train_dataloader_20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20775476",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from going_modular.utils import save_full_model\n",
    "\n",
    "# Set seeds\n",
    "set_seeds(seed = 42)\n",
    "\n",
    "# Keep track of experiment numbers\n",
    "experiment_number = 0\n",
    "\n",
    "# Loop through each DataLoader\n",
    "for dataloader_name, train_dataloader in train_dataloaders.items():\n",
    "    # Loop through the epochs\n",
    "    for epochs in num_epochs:\n",
    "        # Loop through each model name and create a new model instance\n",
    "        for model_name in models:\n",
    "            \n",
    "            # Print out info\n",
    "            experiment_number += 1\n",
    "            print(f\"[INFO] Experiment number: {experiment_number}\")\n",
    "            print(f\"[INFO] Model: {model_name}\")\n",
    "            print(f\"[INFO] DataLoader: {dataloader_name}\")\n",
    "            print(f\"[INFO] Number of epochs: {epochs}\")\n",
    "            \n",
    "            # Select and create the model\n",
    "            if model_name == \"effnetb0\":\n",
    "                model = effnetb0\n",
    "            else:\n",
    "                model = effnetb2\n",
    "                \n",
    "            # Create a new loss and optimizer for every experiment\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(params = model.parameters(),\n",
    "                                        lr = 0.001)\n",
    "            \n",
    "            # Train the target model with target dataloader and track experiments\n",
    "            # Note: Using above modified train function which includes writer parameter.\n",
    "            train(model = model,\n",
    "                 train_dataloader = train_dataloader,\n",
    "                 test_dataloader = test_dataloader,\n",
    "                 optimizer = optimizer,\n",
    "                 loss_fn = loss_fn,\n",
    "                 epochs = epochs,\n",
    "                 device = device, \n",
    "                 writer = create_writer(experiment_name = dataloader_name,\n",
    "                                       model_name = model_name,\n",
    "                                       extra = f\"{epochs}_epochs\"))\n",
    "            \n",
    "            # Save the model to file so we can import it later if need be\n",
    "            save_filepath = f\"{model_name}_{dataloader_name}_{epochs}.epochs.pth\"\n",
    "            save_full_model(model = model,\n",
    "                      target_dir = \"models\",\n",
    "                      model_name = save_filepath)\n",
    "            print(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386ed01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# View summary\n",
    "%reload_ext tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70123af5",
   "metadata": {},
   "source": [
    "##### The best performing model was:\n",
    "   * EffNetB2\n",
    "   * pizza, steak, sushi 20%\n",
    "   * epochs: 10   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc44a7a",
   "metadata": {},
   "source": [
    "## We can share our tensorboad experiment tracking with the help of tensorboard dev\n",
    "\n",
    "Below code is commented out because it is not responding to my current session. This structure can be used to share experiments if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48812791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Upload the results to TensorBoard.dev\n",
    "# !tensorboard dev upload --logdir runs \\\n",
    "#     --name \" PyTorch Experiment Tracking: Food Identification model result (1st try)\" \\\n",
    "#     --description \" Comparing results of different model size, amount of training data and training time.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf28bc",
   "metadata": {},
   "source": [
    "### Load in the best model and make prediction with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup best model filepath\n",
    "best_model_path = \"models/effnetb2_data_20_percent_10.epochs.pth\"\n",
    "\n",
    "# Load the saved model\n",
    "best_model = torch.load(best_model_path)\n",
    "\n",
    "# If the model dictionary needs to be loaded, we need to instantiate the model with same amount of features and input/output shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb93f7",
   "metadata": {},
   "source": [
    "###### The goal is to create a foodIdentify model that performs well enough and is able to run on a mobile device / web browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f35889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model file size\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the model size in bytes then convert it to megabytes\n",
    "effnetb2_model_size = Path(best_model_path).stat().st_size // (1024*1024)\n",
    "print(f\"EfficinetNetB2 feature extractor model size: {effnetb2_model_size} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions to make prediction on images and plot them\n",
    "from going_modular.predictions import pred_and_plot_image\n",
    "\n",
    "# Get a random list of 3image path names from the test dataset\n",
    "import random\n",
    "num_images_to_plot = 3\n",
    "test_image_path_list = list(Path(image_path_20/ \"test\").glob(\"*/*.jpg\"))\n",
    "test_image_path_sample = random.sample(test_image_path_list,\n",
    "                                      k = num_images_to_plot)\n",
    "for image_path in test_image_path_sample:\n",
    "    pred_and_plot_image(model = best_model,\n",
    "                       image_path = image_path,\n",
    "                       class_names = class_names,\n",
    "                       image_size = (224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb7e15",
   "metadata": {},
   "source": [
    "#### Testing model on a custom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806abcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading custom image\n",
    "# Download the image\n",
    "import requests\n",
    "\n",
    "# Setup custom image path\n",
    "custom_image_path1 = Path(\"data/hidden_pizza.png\")\n",
    "\n",
    "# Download the image if it doesn't exist (hidden_pizza.png)\n",
    "if not custom_image_path1.is_file():\n",
    "    with open(custom_image_path1, \"wb\") as f:\n",
    "        request1 = requests.get(\"https://github.com/aayush2058/Food-identification-PyTorch-/raw/main/data/hidden_pizza.png\")\n",
    "        print(f\"Downloading {custom_image_path1}.... \")\n",
    "        f.write(request1.content)\n",
    "        print(\"successful\") \n",
    "        \n",
    "else:\n",
    "    print(f\"{custom_image_path1} already exists, skipping download...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading custom image\n",
    "import requests\n",
    "\n",
    "# Setup custom image path\n",
    "custom_image_path2 = Path(\"data/sushi_served.png\")\n",
    "        \n",
    "# Download the image if it doesn't exist (sushi_served.png)\n",
    "if not custom_image_path2.is_file():\n",
    "    with open(custom_image_path2, \"wb\") as f:\n",
    "        request2 = requests.get(\"https://github.com/aayush2058/Food-identification-PyTorch-/raw/main/data/sushi_served.png\")\n",
    "        print(f\"Downloading {custom_image_path2}.... \")\n",
    "        f.write(request2.content)\n",
    "        print(\"successful\")   \n",
    "else:\n",
    "    print(f\"{custom_image_path2} already exists, skipping download...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions to make predictions.\n",
    "\n",
    "Main reference for code creation: https://www.learnpytorch.io/06_pytorch_transfer_learning/#6-make-predictions-on-images-from-the-test-set \n",
    "\"\"\"\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Predict on a target image with a target model\n",
    "# Function created in: https://www.learnpytorch.io/06_pytorch_transfer_learning/#6-make-predictions-on-images-from-the-test-set\n",
    "def pred_and_plot_image(\n",
    "    model: torch.nn.Module,\n",
    "    class_names: List[str],\n",
    "    image_path: str,\n",
    "    image_size: Tuple[int, int] = (224, 224),\n",
    "    transform: torchvision.transforms = None,\n",
    "    device: torch.device = device,\n",
    "):\n",
    "    \"\"\"Predicts on a target image with a target model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A trained (or untrained) PyTorch model to predict on an image.\n",
    "        class_names (List[str]): A list of target classes to map predictions to.\n",
    "        image_path (str): Filepath to target image to predict on.\n",
    "        image_size (Tuple[int, int], optional): Size to transform target image to. Defaults to (224, 224).\n",
    "        transform (torchvision.transforms, optional): Transform to perform on image. Defaults to None which uses ImageNet normalization.\n",
    "        device (torch.device, optional): Target device to perform prediction on. Defaults to device.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    # Create transformation for image (if one doesn't exist)\n",
    "    if transform is not None:\n",
    "        image_transform = transform\n",
    "    else:\n",
    "        image_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(image_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    ### Predict on image ###\n",
    "\n",
    "    # Make sure the model is on the target device\n",
    "    model.to(device)\n",
    "\n",
    "    # Turn on model evaluation mode and inference mode\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Transform and add an extra dimension to image (model requires samples in [batch_size, color_channels, height, width])\n",
    "        transformed_image = image_transform(img).unsqueeze(dim=0)\n",
    "\n",
    "        # Make a prediction on image with an extra dimension and send it to the target device\n",
    "        target_image_pred = model(transformed_image.to(device))\n",
    "\n",
    "    # Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n",
    "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
    "\n",
    "    # Convert prediction probabilities -> prediction labels\n",
    "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
    "\n",
    "    # Plot image with predicted label and probability\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.title(\n",
    "        f\"Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs.max():.3f}\"\n",
    "    )\n",
    "    plt.axis(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8033fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred_and_plot_image(model = best_model,\n",
    "                   image_path = custom_image_path1,\n",
    "                   class_names = class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred_and_plot_image(model = best_model,\n",
    "                   image_path = custom_image_path2,\n",
    "                   class_names = class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b92156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred_and_plot_image(model = best_model,\n",
    "                   image_path = Path(\"data/pizza_test.jpg\"),\n",
    "                   class_names = class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cfbe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred_and_plot_image(model = best_model,\n",
    "                   image_path = Path(\"data/eating_sushi.jpg\"),\n",
    "                   class_names = class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49010d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
